abline(v = diff(by(y, tr, mean)), col = "blue", lwd = 2)
# Is the attested difference different from what we would expect by chance?
p.value <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$p.value
t <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$statistic
#Save in DF
auc.pvalues[1,l] <- p.value
auc.pvalues[2,l] <- t
}
for (l in 1:13)
{
print(levels(auc.bins_change$variable)[l+1])
auc.bins_subset <- subset(auc.bins_change,variable=='lda.full'| variable==levels(auc.bins_change$variable)[l+1])
tr <- factor(auc.bins_subset$variable)
y <- auc.bins_subset$value
#Mean differences
diff_original <- diff(by(y, tr, mean))
dist <- replicate(2000, diff(by(y, sample(tr, length(tr), FALSE), mean)))
hist(dist, xlim = c(-0.5, 0.5), col = "black", breaks = 100)
abline(v = diff(by(y, tr, mean)), col = "blue", lwd = 2)
# Is the attested difference different from what we would expect by chance?
p.value <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$p.value
t <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$statistic
#Save in DF
auc.pvalues[1,l] <- p.value
auc.pvalues[2,l] <- t
}
?data.frame
#Prepare the data
auc.bins$random_classifier <- rowMeans(random_classifier.df)
auc.bins_change <- melt(auc.bins, id=c('bins'))
auc.pvalues <- data.frame(matrix(ncol=length(levels(auc.bins_change$variable))-1, nrow = 2))
len <- length(levels(auc.bins_change$variable))-1
for (l in 1:len)
{
print(levels(auc.bins_change$variable)[l+1])
auc.bins_subset <- subset(auc.bins_change,variable=='lda.full'| variable==levels(auc.bins_change$variable)[l+1])
tr <- factor(auc.bins_subset$variable)
y <- auc.bins_subset$value
#Mean differences
diff_original <- diff(by(y, tr, mean))
dist <- replicate(2000, diff(by(y, sample(tr, length(tr), FALSE), mean)))
hist(dist, xlim = c(-0.5, 0.5), col = "black", breaks = 100)
abline(v = diff(by(y, tr, mean)), col = "blue", lwd = 2)
# Is the attested difference different from what we would expect by chance?
p.value <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$p.value
t <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$statistic
#Save in DF
auc.pvalues[1,l] <- p.value
auc.pvalues[2,l] <- t
}
levels(auc.bins_change$variable)[1:2]
levels(auc.bins_change$variable)[2:14]
#Prepare the data
auc.bins$random_classifier <- rowMeans(random_classifier.df)
auc.bins_change <- melt(auc.bins, id=c('bins'))
auc.pvalues <- data.frame(matrix(ncol=length(levels(auc.bins_change$variable))-1, nrow = 2))
colnames(auc.pvalues) <-  levels(auc.bins_change$variable)[2:14]
len <- length(levels(auc.bins_change$variable))-1
for (l in 1:len)
{
print(levels(auc.bins_change$variable)[l+1])
auc.bins_subset <- subset(auc.bins_change,variable=='lda.full'| variable==levels(auc.bins_change$variable)[l+1])
tr <- factor(auc.bins_subset$variable)
y <- auc.bins_subset$value
#Mean differences
diff_original <- diff(by(y, tr, mean))
dist <- replicate(2000, diff(by(y, sample(tr, length(tr), FALSE), mean)))
hist(dist, xlim = c(-0.5, 0.5), col = "black", breaks = 100)
abline(v = diff(by(y, tr, mean)), col = "blue", lwd = 2)
# Is the attested difference different from what we would expect by chance?
p.value <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$p.value
t <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$statistic
#Save in DF
auc.pvalues[1,l] <- p.value
auc.pvalues[2,l] <- t
}
View(auc.pvalues)
row.names(auc.pvalues) <- c('pvalue', 'tvalue')
View(auc.bins_subset)
View(auc.bins)
View(auc.bins_change)
View(auc.pvalues)
library(MASS) # NB: this will mask dplyr::select
##TOPLINE (the best we can do)
calibrationTrain <- calibration_data
calibrationTest <- calibration_data
for (b in 1: length(bins)) {
calibrationTrain <- subset(calibration_data, !(id %in% bins[[b]]$id))
calibrationTest <- subset(calibration_data, !(id %in% bins[[b]]$id)) #NB: Same data for training and testing
###  TRAINING + TEST
LDA_training.coord.dist(calibrationTrain)
LDA_test.coord.dist(calibrationTest, v_lda, b_lda, m_pca, all_data_columns, n_pca)
lda.score.te <- lda_measure_te.df$lda_measure
lda.label.te <- lda_measure_te.df$Deviation
lda.roc.topline <- roc(lda.label.te, lda.score.te)
lda.topline.auc <- lda.roc.topline$auc
auc.bins$topline[b] <- lda.roc.topline$auc
#assign(paste0('lda_full.roc.te',b), lda.roc.te)
}
#### CALIBRATION DATA ####
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
## EXTRACTING and ORGANIZING CALIBRATION DATA
# Extracts data from calibration (last version: June 2017) into calibration_data
# Excludes innacurate trials and print the percentage
# Creates data frame normalized_positions.plot: each row contains one time.step with X.Position, Y.Position, Raw.Acceleration, Raw.Time columns among others
source("R_scripts/calibration/extract_calibration_data.R")
## CALIBRATION RESULTS
### Overall description of the results and computation of original/main LDA (subsection 2.2)
source("R_scripts/calibration/calibration_results.R")
#### CALIBRATION DATA ####
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
## EXTRACTING and ORGANIZING CALIBRATION DATA
# Extracts data from calibration (last version: June 2017) into calibration_data
# Excludes innacurate trials and print the percentage
# Creates data frame normalized_positions.plot: each row contains one time.step with X.Position, Y.Position, Raw.Acceleration, Raw.Time columns among others
source("R_scripts/calibration/extract_calibration_data.R")
## CALIBRATION RESULTS
### Overall description of the results and computation of original/main LDA (subsection 2.2)
source("R_scripts/calibration/calibration_results.R")
library(MASS) # NB: this will mask dplyr::select
##TOPLINE (the best we can do)
calibrationTrain <- calibration_data
calibrationTest <- calibration_data
for (b in 1: length(bins)) {
calibrationTrain <- subset(calibration_data, !(id %in% bins[[b]]$id))
calibrationTest <- subset(calibration_data, !(id %in% bins[[b]]$id)) #NB: Same data for training and testing
###  TRAINING + TEST
LDA_training.coord.dist(calibrationTrain)
LDA_test.coord.dist(calibrationTest, v_lda, b_lda, m_pca, all_data_columns, n_pca)
lda.score.te <- lda_measure_te.df$lda_measure
lda.label.te <- lda_measure_te.df$Deviation
lda.roc.topline <- roc(lda.label.te, lda.score.te)
lda.topline.auc <- lda.roc.topline$auc
auc.bins$topline[b] <- lda.roc.topline$auc
#assign(paste0('lda_full.roc.te',b), lda.roc.te)
}
View(auc.bins)
#### CALIBRATION DATA ####
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
## EXTRACTING and ORGANIZING CALIBRATION DATA
# Extracts data from calibration (last version: June 2017) into calibration_data
# Excludes innacurate trials and print the percentage
# Creates data frame normalized_positions.plot: each row contains one time.step with X.Position, Y.Position, Raw.Acceleration, Raw.Time columns among others
source("R_scripts/calibration/extract_calibration_data.R")
## CALIBRATION RESULTS
### Overall description of the results and computation of original/main LDA (subsection 2.2)
source("R_scripts/calibration/calibration_results.R")
### Comparison with other measures normally used in mouse tracking (subsubsection 2.2.1)
source("R_scripts/calibration/comparisons_measures.R")
### Comparison with classifiers which take into account different sets of predictors(subsubsection 2.2.2)
source("R_scripts/calibration/comparison_other_predictors.R")
#### CALIBRATION DATA ####
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
## EXTRACTING and ORGANIZING CALIBRATION DATA
# Extracts data from calibration (last version: June 2017) into calibration_data
# Excludes innacurate trials and print the percentage
# Creates data frame normalized_positions.plot: each row contains one time.step with X.Position, Y.Position, Raw.Acceleration, Raw.Time columns among others
source("R_scripts/calibration/extract_calibration_data.R")
## CALIBRATION RESULTS
### Overall description of the results and computation of original/main LDA (subsection 2.2)
source("R_scripts/calibration/calibration_results.R")
View(auc.bins)
source("R_scripts/calibration/comparisons_measures.R")
### Comparison with classifiers which take into account different sets of predictors(subsubsection 2.2.2)
source("R_scripts/calibration/comparison_other_predictors.R")
source("R_scripts/calibration/permuation_test.R")
source("R_scripts/calibration/permutation_test.R")
package(xtable)
install.packages("xtable")
require(xtable)
require(xtable)
xtable(auc.pvalues)
#### CALIBRATION DATA ####
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
## EXTRACTING and ORGANIZING CALIBRATION DATA
# Extracts data from calibration (last version: June 2017) into calibration_data
# Excludes innacurate trials and print the percentage
# Creates data frame normalized_positions.plot: each row contains one time.step with X.Position, Y.Position, Raw.Acceleration, Raw.Time columns among others
source("R_scripts/calibration/extract_calibration_data.R")
## CALIBRATION RESULTS
### Overall description of the results and computation of original/main LDA (subsection 2.2)
source("R_scripts/calibration/calibration_results.R")
### Comparison with other measures normally used in mouse tracking (subsubsection 2.2.1)
source("R_scripts/calibration/comparisons_measures.R")
### Comparison with classifiers which take into account different sets of predictors(subsubsection 2.2.2)
source("R_scripts/calibration/comparison_other_predictors.R")
### Permutation tests
source("R_scripts/calibration/permutation_test.R")
View(auc.pvalues)
?diff
diff_mean <- function(y, tr, group1, group2) {
mean(y[tr == group1]) - mean(y[tr == group2])
}
ITERATIONS <- 10
#Do permutation test for LDA vs. all the other measures
for (l in 1:len)
{
baseline <- 'lda.full'
comparison <- levels(auc.bins_change$variable)[l+1]
print(comparison)
auc.bins_subset <- subset(auc.bins_change,variable %in% c(baseline, comparison))
tr <- factor(auc.bins_subset$variable)
y <- auc.bins_subset$value
#Mean differences
diff_original <- diff_mean(y, tr, baseline, comparison)
dist <- replicate(ITERATIONS, diff_mean(y, sample(tr, length(tr), FALSE),  baseline, comparison))
#hist(dist, xlim = c(-0.5, 0.5), col = "black", breaks = 100)
#abline(v = diff(by(y, tr, mean)), col = "blue", lwd = 2)
p.value <- sum(dist > diff_original)/ITERATIONS  # one-tailed test
# Is the attested difference different from what we would expect by chance?
#p.value <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$p.value
#t <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$statistic
#Save in DF
auc.pvalues[1,l] <- p.value
auc.pvalues[2,l] <- diff_original
}
auc.pvalues
ITERATIONS <- 100
#Do permutation test for LDA vs. all the other measures
for (l in 1:len)
{
baseline <- 'lda.full'
comparison <- levels(auc.bins_change$variable)[l+1]
print(comparison)
auc.bins_subset <- subset(auc.bins_change,variable %in% c(baseline, comparison))
tr <- factor(auc.bins_subset$variable)
y <- auc.bins_subset$value
#Mean differences
diff_original <- diff_mean(y, tr, baseline, comparison)
dist <- replicate(ITERATIONS, diff_mean(y, sample(tr, length(tr), FALSE),  baseline, comparison))
#hist(dist, xlim = c(-0.5, 0.5), col = "black", breaks = 100)
#abline(v = diff(by(y, tr, mean)), col = "blue", lwd = 2)
p.value <- sum(dist > diff_original)/ITERATIONS  # one-tailed test
# Is the attested difference different from what we would expect by chance?
#p.value <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$p.value
#t <- t.test(dist, y = NULL, alternative = 'two.sided', mu = diff_original)$statistic
#Save in DF
auc.pvalues[1,l] <- p.value
auc.pvalues[2,l] <- diff_original
}
auc.pvalues
auc.bins
histogram(auc.bins[,2])
ggplot(data.frame(auc=c(auc.bins[,2], auc.bins[,5]), labels=c(rep("LDA", 10), rep("DD", 10))), aes(x=auc, fill=labels)) + geom_histogram(position="dodge")
ggplot(data.frame(auc=c(auc.bins[,2], auc.bins[,5]), labels=c(rep("LDA", 10), rep("DD", 10))), aes(x=auc, fill=labels)) + geom_histogram(position="dodge", bins=10)
ggplot(data.frame(auc=c(auc.bins[,2], auc.bins[,4]), labels=c(rep("LDA", 10), rep("DD", 10))), aes(x=auc, fill=labels)) + geom_histogram(position="dodge", bins=10)
ggplot(data.frame(auc=c(auc.bins[,4], auc.bins[,15]), labels=c(rep("LDA", 10), rep("DD", 10))), aes(x=auc, fill=labels)) + geom_histogram(position="dodge", bins=10)
ggplot(data.frame(auc=c(auc.bins[,3], auc.bins[,15]), labels=c(rep("LDA", 10), rep("DD", 10))), aes(x=auc, fill=labels)) + geom_histogram(position="dodge", bins=10)
ggplot(data.frame(auc=c(auc.bins[,2], auc.bins[,15]), labels=c(rep("LDA", 10), rep("DD", 10))), aes(x=auc, fill=labels)) + geom_histogram(position="dodge", bins=10)
ggplot(data.frame(auc=c(auc.bins[,14], auc.bins[,15]), labels=c(rep("LDA", 10), rep("DD", 10))), aes(x=auc, fill=labels)) + geom_histogram(position="dodge", bins=10)
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
source("R_scripts/calibration/extract_calibration_data.R")
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
## EXTRACTING and ORGANIZING CALIBRATION DATA
# Extracts data from calibration (last version: June 2017) into calibration_data
# Excludes innacurate trials and print the percentage
# Creates data frame normalized_positions.plot: each row contains one time.step with X.Position, Y.Position, Raw.Acceleration, Raw.Time columns among others
source("R_scripts/calibration/extract_calibration_data.R")
View(calibration_data)
View(info_calibration)
View(innacurate_data)
str(calibration_data)
calibration_data$Condition
calibration_data$PointChange
as.factor(calibration_data$PointChange)
library(MASS) # NB: this will mask dplyr::select
calibration_data = subset(calibration_data, Polarity != 'uncertain')
calibration_data$Subject <- factor(calibration_data$Subject)
normalized_positions.plot$Subject <- factor(normalized_positions.plot$Subject)
normalized_positions.means.subject <-   ddply(normalized_positions.plot, c("Polarity", "Time.Step.Onset", "Subject"),
function(normalized_positions.plot)c(X.Position.mean=mean(normalized_positions.plot$X.Position, na.rm=T)))
normalized_positions.means <- ddply(normalized_positions.means.subject, c("Polarity", "Time.Step.Onset"),
function(normalized_positions.means.subject)c(X.Position.mean=mean(normalized_positions.means.subject$X.Position, na.rm=T), X.Position.se=se(normalized_positions.means.subject$X.Position, na.rm=T)))
ggplot(normalized_positions.means.subject, aes(x=Time.Step.Onset, y=X.Position.mean, color=Subject, group=Subject)) +
geom_point(size=0.5) + geom_line() +
expand_limits(x=c(-1.5,1.5)) + theme_minimal()+geom_vline(aes(xintercept=0))+
theme(legend.position = "none") + facet_grid(Polarity~.)
ggplot(subset(normalized_positions.means, Polarity!='uncertain'), aes(x=Time.Step.Onset, y=X.Position.mean, color=Polarity, group=Polarity)) +
geom_point(alpha=.6) + geom_line(alpha=.6) + theme_minimal()+ theme(legend.position = "none") +
ggtitle('Calibration Mean X-Position Onset at Change point') + geom_vline(aes(xintercept=0)) +  scale_colour_brewer(palette="Set1") +
geom_errorbar(aes(ymin=X.Position.mean-X.Position.se, ymax=X.Position.mean+X.Position.se), width=.1, alpha=.4)
normalized_positions.means.subject <- ddply(subset(normalized_positions.plot, Polarity!='uncertain'), c("Polarity", "Time.Step", "Subject"),
function(normalized_positions.plot)c(X.Position.mean=mean(normalized_positions.plot$X.Position, na.rm=T),
Y.Position.mean=mean(normalized_positions.plot$Y.Position, na.rm=T)))
normalized_positions.means.traj <- ddply(normalized_positions.means.subject, c("Polarity", "Time.Step"),
function(normalized_positions.means.subject)c(X.Position.mean=mean(normalized_positions.means.subject$X.Position, na.rm=T),
X.Position.se=se(normalized_positions.means.subject$X.Position, na.rm=T),
Y.Position.mean=mean(normalized_positions.means.subject$Y.Position, na.rm=T),
Y.Position.se=se(normalized_positions.means.subject$Y.Position, na.rm=T)))
ggplot(normalized_positions.means.traj, aes(x=X.Position.mean, y=Y.Position.mean, color=Polarity, group=Polarity)) +
geom_point(alpha=.6, size=1) +
ggtitle('Calibration Mean trajectories')+
geom_errorbarh(aes(xmin=X.Position.mean-X.Position.se, xmax=X.Position.mean+X.Position.se)) +
theme_minimal() +
theme(legend.position = "none") +
scale_colour_brewer(palette="Set1")
ggplot(normalized_positions.means.traj, aes(x=X.Position.mean, y=Y.Position.mean, color=Polarity, group=Polarity)) +
geom_point(alpha=.6, size=1) +
ggtitle('Calibration Mean trajectories')+
geom_errorbarh(aes(xmin=X.Position.mean-X.Position.se, xmax=X.Position.mean+X.Position.se)) +
theme_minimal() +
theme(legend.position = "none") +
expand_limits(x=c(-1.5,1.5)) +
scale_colour_brewer(palette="Set1")
ggplot(normalized_positions.means.subject, aes(x=X.Position.mean, y=Y.Position.mean, color=Subject, group=Subject)) +
geom_point(size=0.5) +
ggtitle('Mean Trajectories per subject') +
theme_minimal() +
theme(legend.position = "top") +
expand_limits(x=c(-1.5,1.5)) +
facet_grid(Polarity~.)
ggplot(normalized_positions.means.subject, aes(x=X.Position.mean, y=Y.Position.mean, color=Subject, group=Subject)) +
geom_point(size=0.5) +
ggtitle('Mean Trajectories per subject') +
theme_minimal() +
theme(legend.position = "none") +
expand_limits(x=c(-1.5,1.5)) +
facet_grid(Polarity~.)
ggplot(subset(normalized_positions.means, Polarity!='uncertain'), aes(x=Time.Step.Onset, y=X.Position.mean, color=Polarity, group=Polarity)) +
geom_point(alpha=.6) + geom_line(alpha=.6) + theme_minimal()+ theme(legend.position = "none") +
ggtitle('Calibration Mean X-Position Onset at Change point') + geom_vline(aes(xintercept=0)) +  scale_colour_brewer(palette="Set1") +
geom_errorbar(aes(ymin=X.Position.mean-X.Position.se, ymax=X.Position.mean+X.Position.se), width=.1, alpha=.4)
normalized_positions.means.subject <-   ddply(normalized_positions.plot, c("Polarity", "Time.Step.Onset", "Subject", "Point.Change"),
function(normalized_positions.plot)c(X.Position.mean=mean(normalized_positions.plot$X.Position, na.rm=T)))
normalized_positions.means.subject <-   ddply(normalized_positions.plot, c("Polarity", "Time.Step.Onset", "Subject", "PointChange"),
function(normalized_positions.plot)c(X.Position.mean=mean(normalized_positions.plot$X.Position, na.rm=T)))
normalized_positions.means <- ddply(normalized_positions.means.subject, c("Polarity", "Time.Step.Onset", "PointChange"),
function(normalized_positions.means.subject)c(X.Position.mean=mean(normalized_positions.means.subject$X.Position, na.rm=T), X.Position.se=se(normalized_positions.means.subject$X.Position, na.rm=T)))
normalized_positions.means.subject <-   ddply(normalized_positions.plot, c("Polarity", "Time.Step.Onset", "Subject", "PointChange"),
function(normalized_positions.plot)c(X.Position.mean=mean(normalized_positions.plot$X.Position, na.rm=T)))
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
## EXTRACTING and ORGANIZING CALIBRATION DATA
# Extracts data from calibration (last version: June 2017) into calibration_data
# Excludes innacurate trials and print the percentage
# Creates data frame normalized_positions.plot: each row contains one time.step with X.Position, Y.Position, Raw.Acceleration, Raw.Time columns among others
source("R_scripts/calibration/extract_calibration_data.R")
## Overall description of the results and computation of original/main LDA (subsection 2.2)
library(MASS) # NB: this will mask dplyr::select
## Subset to deviated and straight trials
calibration_data = subset(calibration_data, Polarity != 'uncertain')
calibration_data$Subject <- factor(calibration_data$Subject)
normalized_positions.plot$Subject <- factor(normalized_positions.plot$Subject)
normalized_positions.means.subject <-   ddply(normalized_positions.plot, c("Polarity", "Time.Step.Onset", "Subject", "PointChange"),
function(normalized_positions.plot)c(X.Position.mean=mean(normalized_positions.plot$X.Position, na.rm=T)))
normalized_positions.means <- ddply(normalized_positions.means.subject, c("Polarity", "Time.Step.Onset", "PointChange"),
function(normalized_positions.means.subject)c(X.Position.mean=mean(normalized_positions.means.subject$X.Position, na.rm=T), X.Position.se=se(normalized_positions.means.subject$X.Position, na.rm=T)))
ggplot(subset(normalized_positions.means, Polarity!='uncertain'), aes(x=Time.Step.Onset, y=X.Position.mean, color=Polarity, group=Polarity)) +
geom_point(alpha=.6) + geom_line(alpha=.6) + theme_minimal()+ theme(legend.position = "none") +
ggtitle('Calibration Mean X-Position Onset at Change point') + geom_vline(aes(xintercept=0)) +  scale_colour_brewer(palette="Set1") +
geom_errorbar(aes(ymin=X.Position.mean-X.Position.se, ymax=X.Position.mean+X.Position.se), width=.1, alpha=.4) + facet_grid(~PointChange)
LDA_training.coord.dist(calibration_data)
save(m_pca, v_lda, b_lda, n_pca, all_data_columns, file="LDA-Full.RData")
calibration_data <- dplyr::full_join(lda_measure.df, calibration_data, by=c("Subject", "Item.number", "Expected_response"))
normalized_positions.plot <- dplyr::full_join(lda_measure.df, normalized_positions.plot, by=c("Subject", "Item.number", "Expected_response"))
plot_measure(calibration_data, "lda_measure_full", "Polarity")
normalized_positions.plot$lda_measure_full_cut <- cut(normalized_positions.plot$lda_measure_full, 5)
calibration_data$lda_measure_full_cut <- cut(calibration_data$lda_measure_full, 5)
calibration_data$id <- 1:nrow(calibration_data)
deviated = calibration_data %>%
filter(Polarity=='deviated')%>%
dplyr::select(id)
deviated$id <- sample(deviated$id)
straight = calibration_data %>%
filter(Polarity=='straight')%>%
dplyr::select(id)
straight$id <- sample(straight$id)
bins  <- rep(1:10, nrow(straight) / 10)
try <- split(straight, bins)
bin1 <- try$`1`
bin2 <- try$`2`
bin3 <- try$`3`
bin4 <- try$`4`
bin5 <- try$`5`
bin6 <- try$`6`
bin7 <- try$`7`
bin8 <- try$`8`
bin9 <- try$`9`
bin10 <- try$`10`
bins  <- rep(1:10, nrow(deviated) / 10)
try <- split(deviated, bins)
bin1 <- rbind(bin1, try$`1`)
bin2 <- rbind(bin2, try$`2`)
bin3 <- rbind(bin3, try$`3`)
bin4 <- rbind(bin4, try$`4`)
bin5 <- rbind(bin5, try$`5`)
bin6 <- rbind(bin6, try$`6`)
bin7 <- rbind(bin7, try$`7`)
bin8 <- rbind(bin8, try$`8`)
bin9 <- rbind(bin9, try$`9`)
bin10 <- rbind(bin10, try$`10`)
rm(try)
bins <- list(bin1, bin2, bin3, bin4, bin5, bin6, bin7, bin8, bin9, bin10)
x <- paste0('x', sprintf("%03d", c(1:101)))
y <- paste0('y', sprintf("%03d", c(1:101)))
auc.bins <- data.frame(bins = c(1:10),
lda.full=c(1:10),
lda.coord.vel=c(1:10),
lda.acc=c(1:10),
lda.coord=c(1:10),
lda.coord.delta.deltadelta=c(1:10),
lda.coord.delta=c(1:10),
lda.deltadelta=c(1:10),
lda.logratio=c(1:10),
logratio=c(1:10),
xflips=c(1:10),
maxdeviation=c(1:10),
accflips=c(1:10),
topline=c(1:10))
#Testing classifier per bin and obtaining ROC and AUC
for (b in 1: length(bins)) {
calibrationTrain <- subset(calibration_data, !(id %in% bins[[b]]$id))
calibrationTest <- subset(calibration_data, id %in% bins[[b]]$id)
## LDA with Coordinates, Delta, DeltaDelta
###  TRAINING + TEST
LDA_training.coord.dist(calibrationTrain)
LDA_test.coord.dist(calibrationTest, v_lda, b_lda, m_pca, all_data_columns, n_pca)
#ROC and AUC
lda.score.te <- lda_measure_te.df$lda_measure
lda.label.te <- lda_measure_te.df$Deviation
lda.roc.te <- roc(lda.label.te, lda.score.te)
auc.bins$lda.full[b] <- lda.roc.te$auc
assign(paste0('lda_full.roc.te',b), lda.roc.te)
}
#plot ROC and aUC
png(filename='R_scripts/graphs/ROC:LDA-FULL.png', width = 7, height = 7, units = 'in', res = 300)
plot.roc(smooth(lda_full.roc.te1), print.auc = FALSE, col="red", main='Original Linear Discriminant Analysis (Coord, Vel, Acc)')
plot.roc(smooth(lda_full.roc.te2), print.auc = FALSE, col="red", add=TRUE)
plot.roc(smooth(lda_full.roc.te3), print.auc = FALSE, col="red", add=TRUE)
plot.roc(smooth(lda_full.roc.te4), print.auc = FALSE, col="red", add=TRUE)
plot.roc(smooth(lda_full.roc.te5), print.auc = FALSE, col="red", add=TRUE)
plot.roc(smooth(lda_full.roc.te6), print.auc = FALSE, col="red", add=TRUE)
plot.roc(smooth(lda_full.roc.te7), print.auc = FALSE, col="red", add=TRUE)
plot.roc(smooth(lda_full.roc.te8), print.auc = FALSE, col="red", add=TRUE)
plot.roc(smooth(lda_full.roc.te9), print.auc = FALSE, col="red", add=TRUE)
plot.roc(smooth(lda_full.roc.te10), print.auc = FALSE, col="red", add=TRUE)
text(0.5, 0, paste("MEAN AUC=", round(mean(auc.bins$lda.full), digits=3)),
cex = 1)
dev.off()
rm(lda_full.roc.te1,lda_full.roc.te10,lda_full.roc.te2,lda_full.roc.te3,lda_full.roc.te4,lda_full.roc.te5,lda_full.roc.te6, lda_full.roc.te7,lda_full.roc.te8,lda_full.roc.te9)
#Topline and Random classifiers
source("R_scripts/calibration/topline.R")
source("R_scripts/calibration/random_classifier.R")
#### CALIBRATION DATA ####
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
## CHARGE FUNCTIONS FOR LDA TRAINING
source("R_scripts/calibration/LDA.R")
## EXTRACTING and ORGANIZING CALIBRATION DATA
# Extracts data from calibration (last version: June 2017) into calibration_data
# Excludes innacurate trials and print the percentage
# Creates data frame normalized_positions.plot: each row contains one time.step with X.Position, Y.Position, Raw.Acceleration, Raw.Time columns among others
source("R_scripts/calibration/extract_calibration_data.R")
## CALIBRATION RESULTS
### Overall description of the results and computation of original/main LDA (subsection 2.2)
source("R_scripts/calibration/calibration_results.R")
### Comparison with other measures normally used in mouse tracking (subsubsection 2.2.1)
source("R_scripts/calibration/comparisons_measures.R")
### Comparison with classifiers which take into account different sets of predictors(subsubsection 2.2.2)
source("R_scripts/calibration/comparison_other_predictors.R")
### Permutation tests
source("R_scripts/calibration/permutation_test.R")
View(auc.bins_change)
View(auc.bins)
View(auc.pvalues)
## CLEAN ENVIRONMENT
rm(list = ls())
## CHARGE PACKAGES
source("R_scripts/packages.R")
source("R_scripts/negation/extracting_negation_data.R")
source("R_scripts/negation/negation_results.R")
